{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D35zQIUb6jNX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSYiRoIhnknw"
   },
   "source": [
    "## **Importing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "id": "Tv8XNKdB6luh",
    "outputId": "d48c4648-3253-412f-fbfd-16f20e4aa81c"
   },
   "outputs": [],
   "source": [
    "# Import main data frame\n",
    "df = pd.read_json(\"data/nlp-chatbot-analysis_data/training-set/chatbot-arena-conversations.jsonl.gz\",\n",
    "                  compression='gzip',\n",
    "                  lines=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "2DQ48S9i7Xki",
    "outputId": "335445c6-d562-4b24-ac8c-7eb04bdbb792"
   },
   "outputs": [],
   "source": [
    "# Auxiliary Datasets\n",
    "\n",
    "# Embedding Data -- we will use this data in the \"Embedding Data\" section\n",
    "prompt_embeddings = np.load(\n",
    "    \"data/nlp-chatbot-analysis_data/training-set/chatbot-arena-prompts-embeddings.npy\"\n",
    ")\n",
    "\n",
    "response_a_embeddings = np.load(\n",
    "    \"data/nlp-chatbot-analysis_data/training-set/chatbot-arena-model_a_response-embeddings.npy\"\n",
    ")\n",
    "\n",
    "response_b_embeddings = np.load(\n",
    "    \"data/nlp-chatbot-analysis_data/training-set/chatbot-arena-model_b_response-embeddings.npy\"\n",
    ")\n",
    "\n",
    "# Topic Modeling and Hardness Score Data -- we will use this data in the \"Topic Modeling and Hardness Score Data\" section\n",
    "topic_and_hardness = pd.read_json(\n",
    "     \"data/nlp-chatbot-analysis_data/training-set/chatbot-arena-gpt3-scores.jsonl.gz\",\n",
    "     lines=True,\n",
    "     compression=\"gzip\"\n",
    ")\n",
    "\n",
    "topic_and_hardness.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkALnIUlzDff"
   },
   "outputs": [],
   "source": [
    "# Import main test data\n",
    "df_test = pd.read_json(\"data/nlp-chatbot-analysis_data/test-set/arena-test-set-topic-modeling.jsonl.gz\",\n",
    "                  compression='gzip',\n",
    "                  lines=True)\n",
    "df_test.head(1)\n",
    "\n",
    "test_prompts = pd.read_json(\"data/nlp-chatbot-analysis_data/test-set/arena-test-set-prompt-and-responses.jsonl.gz\",\n",
    "                  compression='gzip',\n",
    "                  lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rxcqZMD8GkR"
   },
   "outputs": [],
   "source": [
    "# Test embedding Data -- we will use this data in the \"Embedding Data\" section\n",
    "test_response_a_embeddings = np.load(\n",
    "    \"data/nlp-chatbot-analysis_data/test-set/arena-test-set-model_a_response-embeddings.npy\"\n",
    ")\n",
    "\n",
    "test_response_b_embeddings = np.load(\n",
    "    \"data/nlp-chatbot-analysis_data/test-set/arena-test-set-model_b_response-embeddings.npy\"\n",
    ")\n",
    "\n",
    "test_prompt_embeddings = np.load(\n",
    "    \"data/nlp-chatbot-analysis_data/test-set/arena-test-set-prompts-embeddings.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcKBXh-ttzzl"
   },
   "source": [
    "## **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If below throws error, run this cell:\n",
    "# response_a_embeddings = np.delete(response_a_embeddings, all_removed_idx)\n",
    "# response_b_embeddings = np.delete(response_b_embeddings, all_removed_idx)\n",
    "# prompt_embeddings = np.delete(prompt_embeddings,all_removed_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyIqGuWttso3"
   },
   "outputs": [],
   "source": [
    "# Add embeddings to df\n",
    "df[\"prompt_embedding\"] = list(prompt_embeddings)\n",
    "df[\"model_a_response_embedding\"] = list(response_a_embeddings)\n",
    "df[\"model_b_response_embedding\"] = list(response_b_embeddings)\n",
    "\n",
    "#print(df.head(2))\n",
    "#print(prompt_embeddings[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxwK8mN0Soyd"
   },
   "outputs": [],
   "source": [
    "# Extract prompts and prompt lengths\n",
    "df[\"prompt\"] = df[\"conversation_a\"].str[0].str[\"content\"]\n",
    "df[\"prompt_length\"] = df[\"prompt\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaXCbFuqtisQ"
   },
   "outputs": [],
   "source": [
    "# Extract model a and b responses and their lengths\n",
    "df[\"model_a_response\"] = df[\"conversation_a\"].str[1].str[\"content\"]\n",
    "df[\"model_a_response_length\"] = df[\"model_a_response\"].str.len()\n",
    "\n",
    "df[\"model_b_response\"] = df[\"conversation_b\"].str[1].str[\"content\"]\n",
    "df[\"model_b_response_length\"] = df[\"model_b_response\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYgFJJnkah91"
   },
   "outputs": [],
   "source": [
    "# Generate response similarity matrix and then add a column that gives the similarities of each response in the dataframe\n",
    "# Doing this here as it becomes harder once the unsalvagable rows are dropped\n",
    "response_similarities = cosine_similarity(response_a_embeddings, response_b_embeddings)\n",
    "df['response_similarity'] = response_similarities.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnEICfs8t76T",
    "outputId": "30c83f52-d6a0-4373-9204-dd121c5e3ac6"
   },
   "outputs": [],
   "source": [
    "# Removing 10 duplicates from df\n",
    "\n",
    "dupes = df['question_id'].duplicated(keep='first')\n",
    "\n",
    "# Get indices of duplicates\n",
    "dropped_indices = df['question_id'][dupes].index.tolist()\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates(subset=['question_id'], keep='first')\n",
    "print(len(df))\n",
    "\n",
    "print(\"Dropped indices:\", dropped_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNt1tjwNwdqp"
   },
   "outputs": [],
   "source": [
    "# Remove any duplicates from topic_and_hardess\n",
    "topic_and_hardness = topic_and_hardness.drop_duplicates(subset=['question_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ks19EYixujp"
   },
   "outputs": [],
   "source": [
    "# Function to clean topic_and_hardness\n",
    "def cleanLists(df):\n",
    "    count = [1, 2, 3]\n",
    "\n",
    "    for num in count:\n",
    "        # replacing list values in topics\n",
    "        df[f'topic_modeling_{num}'] = np.where(df[f'topic_modeling_{num}'].apply(lambda x: isinstance(x, list)),\n",
    "                                              ','.join(map(str, df[f'topic_modeling_{num}'])), # If found to be list, replace with string\n",
    "                                               df[f'topic_modeling_{num}'] # else, keep value as is\n",
    "                                              )\n",
    "\n",
    "        # replacing nested list values in score value\n",
    "        df[f'score_value_{num}'] = np.where(df[f'score_value_{num}'].apply(lambda x: isinstance(x, list)),\n",
    "                                           df[f'score_value_{num}'][0], # if found to be list, replace with nested value\n",
    "                                           df[f'score_value_{num}']) # else, keep value\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean topic_and_hardness\n",
    "def cleanLists2(df):\n",
    "    count = [1, 2, 3]\n",
    "\n",
    "    for num in count:\n",
    "        # replacing list values in topics\n",
    "        df[f'topic_modeling_{num}'] = np.where(df[f'topic_modeling_{num}'].apply(lambda x: isinstance(x, list)),\n",
    "                                              ','.join(map(str, df[f'topic_modeling_{num}'])), # If found to be list, replace with string\n",
    "                                               df[f'topic_modeling_{num}'] # else, keep value as is\n",
    "                                              )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAGQmXrox4wc",
    "outputId": "56621f2c-0516-40e5-e203-a7acce68f1d2"
   },
   "outputs": [],
   "source": [
    "# Clean t&h\n",
    "topic_and_hardness = cleanLists(topic_and_hardness)\n",
    "\n",
    "# converting floats to integer values\n",
    "topic_and_hardness.loc[23757, 'score_value_1'] = int(topic_and_hardness.loc[23757, 'score_value_1'] * 10)\n",
    "topic_and_hardness.loc[23757, 'score_value_3'] = int(topic_and_hardness.loc[23757, 'score_value_3'] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QC5lQma44fc7"
   },
   "outputs": [],
   "source": [
    "# Extract salvageable rows based on parsing through raw data\n",
    "salvagable_null_rows = topic_and_hardness.loc[[10857, 15368, 20363, 24966],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6H09DnoB49wQ"
   },
   "outputs": [],
   "source": [
    "# Dropna from topic and hardness, and use rest to salvagable df and topic and hardness df seperately to extract topics\n",
    "removed_na = []\n",
    "for index in topic_and_hardness[topic_and_hardness['topic_modeling_1'].isna()].index:\n",
    "    if index not in salvagable_null_rows.index:\n",
    "        removed_na.append(index)\n",
    "topic_and_hardness = topic_and_hardness.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChlTD3MPbHjZ"
   },
   "outputs": [],
   "source": [
    "# Creating a df copy for classification task that keeps response similarity scores\n",
    "class_df = df.copy()\n",
    "\n",
    "# dropping 'response_similarity' from main df\n",
    "df = df.drop(columns=['response_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_removed_idx = dropped_indices + removed_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWEdwFVndzSn"
   },
   "source": [
    "# General Feature Engineering\n",
    "Features to be used across modeling tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_JVv-R-Ss86s",
    "outputId": "ebb57d41-30a3-41e5-c8b8-feed7e6c3149"
   },
   "outputs": [],
   "source": [
    "# All Topic Extraction Tasks\n",
    "topic_regex = r'\\\"topic_modeling\":\\s\"([\\w\\W]+?)\\\"'\n",
    "new_raw_choices = salvagable_null_rows.loc[:,'openai_scores_raw_choices_nested'].astype('str')\n",
    "salvaged_topics = new_raw_choices.str.findall(pat=topic_regex)\n",
    "salvaged_topics = pd.DataFrame(salvaged_topics)\n",
    "salvaged_topics.rename(columns = {'openai_scores_raw_choices_nested':'topics'},\n",
    "                       inplace=True)\n",
    "salvaged_topics['topics'] = salvaged_topics['topics'].str.join(', ')\n",
    "\n",
    "# Creating raw topics dataframe\n",
    "raw_topics = topic_and_hardness['question_id']\n",
    "raw_topics = pd.DataFrame(raw_topics)\n",
    "raw_topics['topics'] = topic_and_hardness['topic_modeling_1'] + ', ' + topic_and_hardness['topic_modeling_2'] + ', ' + topic_and_hardness['topic_modeling_3']\n",
    "\n",
    "all_topics = pd.concat([raw_topics, salvaged_topics])\n",
    "all_topics = all_topics.sort_index()\n",
    "all_topics = all_topics.drop(columns=['question_id'])\n",
    "all_topics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTestTopics(df_test):\n",
    "    \"\"\"\n",
    "    Extract topics from test df\n",
    "    \"\"\"\n",
    "    test_topic_embeddings = df_test.copy()\n",
    "    test_topic_embeddings = cleanLists2(test_topic_embeddings)\n",
    "    test_topic_embeddings['topics'] = test_topic_embeddings['topic_modeling_1'] + ', ' + test_topic_embeddings['topic_modeling_2'] + ', ' + test_topic_embeddings['topic_modeling_3'] \n",
    "\n",
    "\n",
    "    element_types = test_topic_embeddings['topics'].map(type)\n",
    "    rows_to_impute = test_topic_embeddings[test_topic_embeddings['topics'].map(lambda x: isinstance(x, float))].index\n",
    "\n",
    "    imputed_topic = test_topic_embeddings.loc[139,'topics']\n",
    "    \n",
    "    # Imputing Blank Rows with Topics\n",
    "    test_topic_embeddings.loc[rows_to_impute,'topics'] = imputed_topic\n",
    "\n",
    "    return test_topic_embeddings['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTopicEmbeddings(train_topics, df_test):\n",
    "    \"\"\"\n",
    "    Return reduced embeddings for train and test topics\n",
    "    \"\"\"\n",
    "    test_topics = extractTestTopics(df_test)\n",
    "    \n",
    "    # Check if MPS is available\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "    # Topic Embeddings\n",
    "    train_topic_embeddings = []\n",
    "    for topic in train_topics['topics']:\n",
    "        embedding = model.encode(topic)\n",
    "        train_topic_embeddings.append(embedding)\n",
    "\n",
    "    # Test Embeddings\n",
    "    test_topic_embeddings = []\n",
    "    for topic in test_topics:\n",
    "        embedding = model.encode(topic)\n",
    "        test_topic_embeddings.append(embedding)\n",
    "    \n",
    "\n",
    "    # Convert embeddings to numpy array \n",
    "    train_embeddings_array = np.array(train_topic_embeddings)\n",
    "    test_embeddings_array = np.array(test_topic_embeddings)\n",
    "    \n",
    "    # Define UMAP model \n",
    "    umap_model = UMAP(n_neighbors=25, \n",
    "                     n_components=10,  \n",
    "                     min_dist=0.0,\n",
    "                     metric='cosine',\n",
    "                     random_state=42)\n",
    "    \n",
    "    # Fit and transform the embeddings\n",
    "    train_topic_embeddings_reduced = umap_model.fit_transform(train_embeddings_array)\n",
    "    test_topic_embeddings_reduced = umap_model.fit_transform(test_embeddings_array)\n",
    "\n",
    "    return train_topic_embeddings_reduced, test_topic_embeddings_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR PROMPT EMBEDDINGS\n",
    "test_matrix = test_prompt_embeddings\n",
    "\n",
    "# Clustering embeddings\n",
    "k = 50\n",
    "k_means = KMeans(n_clusters=k,\n",
    "               random_state=42)\n",
    "test_cluster_labels = k_means.fit_predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['cluster_label'] = test_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_topic_embeddings, test_topic_embeddings = generateTopicEmbeddings(all_topics, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Jg6VzPRmPU8"
   },
   "source": [
    "# **Task A**\n",
    "\n",
    "Workspace for winner-determination stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCO5FIUScYPm"
   },
   "source": [
    "## Initial Data Preparation\n",
    "* Here we begin preparing the class_df, which is our raw dataset that will be used during train/validation. And will make up the raw data for what will train our final test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOsDVy94ijix"
   },
   "outputs": [],
   "source": [
    "# Absolute Response Length Difference\n",
    "class_df['response_length_difference'] = np.absolute(class_df['model_a_response_length'] - class_df['model_b_response_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoViJrjgjt_w"
   },
   "outputs": [],
   "source": [
    "# Fixing skew with log transforms\n",
    "class_df['log_prompt_length'] = np.log(class_df['prompt_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ap6xz1eDkQfb"
   },
   "outputs": [],
   "source": [
    "# changing some column names\n",
    "class_df.rename(columns={'model_a_response':'response_a','model_b_response': 'response_b',\n",
    "                         'model_a_response_length':'response_a_length',\n",
    "                         'model_b_response_length':'response_b_length'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0K4LOT9oocpT"
   },
   "outputs": [],
   "source": [
    "# Score Stuff\n",
    "\n",
    "# Extract topics from salvagable null rows:\n",
    "score_regex = r'\\\"score_value\\\":\\s(\\d)+'\n",
    "# Salvagable raw choices used above in topic_extraction\n",
    "salvagable_raw_choices = salvagable_null_rows.loc[:,'openai_scores_raw_choices_nested'].astype('str')\n",
    "\n",
    "\n",
    "salvagable_raw_scores = salvagable_raw_choices.str.findall(pat=score_regex)\n",
    "\n",
    "# Converting strings to ints then taking means\n",
    "for index in salvagable_raw_scores.index:\n",
    "    salvagable_raw_scores[index] = [int(item) for item in salvagable_raw_scores[index]]\n",
    "    salvagable_raw_scores[index] = np.mean(salvagable_raw_scores[index])\n",
    "\n",
    "salvagable_raw_scores.name = 'avg_hardness_score'\n",
    "\n",
    "# Average of scores from topic_and_hardness\n",
    "score_values_core = ((topic_and_hardness['score_value_1'] + topic_and_hardness['score_value_2'] + topic_and_hardness['score_value_3'])/3).astype('int')\n",
    "\n",
    "# Concatenation of all _scores\n",
    "all_scores = pd.concat([salvagable_raw_scores, score_values_core])\n",
    "all_scores = pd.Series(all_scores, name='avg_hardness_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EQf2Zo8pJrW"
   },
   "outputs": [],
   "source": [
    "# Add average scores to class_df\n",
    "class_df['hardness_score'] = all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CboS7STSkH1O"
   },
   "source": [
    "### Bradley Terry Modeling\n",
    "* Here we extract Bradley Terry scores for use in our logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPDleT3PlYWW"
   },
   "outputs": [],
   "source": [
    "# BT Implementation with Helper Functions\n",
    "def btNumerator(skill_levels, df, current_model):\n",
    "    \"\"\"\n",
    "    Helper Function. Returns the numerator for a Bradley-Terry Calculation per wikipedia equation 5\n",
    "    \"\"\"\n",
    "    numerator_outcome = 0\n",
    "    combatting_models = df.index\n",
    "    model_a_skill = skill_levels.loc[current_model]\n",
    "\n",
    "    # performing the summation here\n",
    "    for i in range(len(df)):\n",
    "        # row denotes model a wins against model b. Use iloc because we are using the index location of each model, not label\n",
    "        model_a_wins = df.iloc[i]\n",
    "\n",
    "        model_b_skill = skill_levels.loc[combatting_models[i]]\n",
    "\n",
    "        calculation = model_a_wins*(model_b_skill/(model_a_skill+model_b_skill))\n",
    "        numerator_outcome += calculation\n",
    "\n",
    "    return numerator_outcome\n",
    "\n",
    "\n",
    "def btDenominator(skill_levels, df, current_model):\n",
    "    \"\"\"\n",
    "    Helper Function. Returns the denominator for a Bradley-Terry Calculation per wikipedia equation 5\n",
    "    \"\"\"\n",
    "    denominator_outcome = 0\n",
    "    combatting_models = df.index\n",
    "    model_a_skill = skill_levels.loc[current_model]\n",
    "\n",
    "    # performing the summation here\n",
    "    for i in range(len(df)):\n",
    "        # row here denotes model b wins against model a. Use iloc because we are using the index location of each model, not label\n",
    "        model_b_wins = df.iloc[i]\n",
    "\n",
    "        model_b_skill = skill_levels.loc[combatting_models[i]]\n",
    "\n",
    "        calculation = model_b_wins*(1/(model_a_skill+model_b_skill))\n",
    "        denominator_outcome += calculation\n",
    "\n",
    "    return denominator_outcome\n",
    "\n",
    "def bradleyTerry(df, skill_levels, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    My implementation of bradley-terry based off of the algorithm on wikipedia. Specifically\n",
    "    The algorithm which is noted to reach \"convergence\" faster. Will return a new list\n",
    "    of skill_levels for each model, and run until convergence is met (set at when all skill levels < 1e-8)\n",
    "    or until max iterations is reached (set at 1000)\n",
    "    \"\"\"\n",
    "    # Will run until convergence condition is met, which is when new_skill_levels < 1e-8 for all models\n",
    "    iterations = 0\n",
    "    threshold_flag = False\n",
    "    while (threshold_flag == False) and (max_iterations != iterations):\n",
    "        # Creating a temporary list that we will use to compare against old values\n",
    "        new_skill_levels = []\n",
    "\n",
    "        # update parameters, process repeats until all parameters meet the condition of |new_skill_level - olc_skill_level| < threshold\n",
    "        for current_model, model_pairs in df.iterrows():\n",
    "            # For the numerator, I just need all columns pertaining to other models\n",
    "            numerator = btNumerator(skill_levels, df.loc[current_model, df.index[df.index != current_model]], current_model)\n",
    "\n",
    "            # for the denominator, I need all rows pertaining to other models for the current model column\n",
    "            denominator = btDenominator(skill_levels, df.loc[df.index[df.index != current_model], current_model], current_model)\n",
    "\n",
    "            new_skill_level = numerator/denominator\n",
    "\n",
    "            # update the relevant parameter\n",
    "            new_skill_levels.append(new_skill_level)\n",
    "\n",
    "        # convert new_skill_levels into series for vector wise operations\n",
    "        new_skill_levels = pd.Series(new_skill_levels, index=skill_levels.index)\n",
    "\n",
    "        # Normalize all parameters by geometric mean:\n",
    "        geometric_mean = (np.prod(new_skill_levels))**(1/skill_levels.shape[0])\n",
    "\n",
    "        new_skill_levels = new_skill_levels/geometric_mean\n",
    "\n",
    "        # confirm threshold is not met, if so, continue calculating BT for all models. .all returns true when entire series is true. If true, convergence\n",
    "        # met\n",
    "        if (np.abs(new_skill_levels-skill_levels) < 1e-8).all():\n",
    "            skill_levels = new_skill_levels\n",
    "            threshold_flag = True\n",
    "        else:\n",
    "            skill_levels = new_skill_levels\n",
    "        iterations += 1\n",
    "    print(f\"Finding BT took {iterations} operations until convergence\")\n",
    "    return skill_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iv5c5gfJlzis",
    "outputId": "c6a86365-e0c3-4abf-ce91-a9286cf1df47"
   },
   "outputs": [],
   "source": [
    "# Creating a sub dataframe of all model pairings in the dataset\n",
    "model_pairings = df[['model_a', 'model_b', 'winner']]\n",
    "\n",
    "# Surpressing warnings for style\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Making indicator column of a victory by model pairing to create pairwise\n",
    "# comparison matrix\n",
    "model_pairings['winning_model'] = model_pairings.apply(lambda x: x[x['winner']] if x['winner'] != 'tie' and x['winner'] != 'tie (bothbad)' else 0, axis=1)\n",
    "model_pairings['model_a_win'] = model_pairings.apply(lambda x: 1 if x['winning_model'] == x['model_a'] else 0, axis=1)\n",
    "model_pairings['model_b_win'] = model_pairings.apply(lambda x: 1 if x['winning_model'] == x['model_b'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pyqIyLDmKlw"
   },
   "outputs": [],
   "source": [
    "# Creating pairwise win matrixes, two iterations then adding both to full gaps\n",
    "pairwise_win_matrix_a = model_pairings.pivot_table(\n",
    "    index='model_a',\n",
    "    columns='model_b',\n",
    "    values='model_a_win',\n",
    "    aggfunc= 'sum'\n",
    ")\n",
    "pairwise_win_matrix_b = model_pairings.pivot_table(\n",
    "    index='model_b',\n",
    "    columns='model_a',\n",
    "    values='model_b_win',\n",
    "    aggfunc= 'sum'\n",
    ")\n",
    "true_pairwise_win_matrix = pairwise_win_matrix_a + pairwise_win_matrix_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pv0qdUDpmZ2I"
   },
   "outputs": [],
   "source": [
    "# Now to calculate bradley-terry scores:\n",
    "# initializing model_scores\n",
    "init_model_skill_levels = pd.Series(np.ones(true_pairwise_win_matrix.shape[0]), index=true_pairwise_win_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDNuxOUUmdor",
    "outputId": "2f6030c9-a7a8-4dc9-aa54-ff23115d0dbb"
   },
   "outputs": [],
   "source": [
    "# Scoring models with BT\n",
    "bt_model_skill_levels = bradleyTerry(true_pairwise_win_matrix, init_model_skill_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "FTL1diiCmj-a",
    "outputId": "c6890830-14ec-4234-f72f-176aa3690792"
   },
   "outputs": [],
   "source": [
    "# Sorting by values descending and comparing to rankings we found with elo for sanity check\n",
    "bt_model_skill_levels.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZNoIhUMpmFm"
   },
   "outputs": [],
   "source": [
    "# adding model bt scores to dataset. Creating as function so it can be used to transform test set later\n",
    "def btAllocate(df, mapping):\n",
    "    df['model_a_skill'] = df['model_a'].map(mapping)\n",
    "    df['model_b_skill'] = df['model_b'].map(mapping)\n",
    "    df['pr_model_a_win'] = df['model_a_skill'] / (df['model_a_skill'] + df['model_b_skill'])\n",
    "    df['pr_model_b_win'] = df['model_b_skill'] / (df['model_a_skill'] + df['model_b_skill'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZphvEbFpn-y"
   },
   "outputs": [],
   "source": [
    "class_df = btAllocate(class_df, bt_model_skill_levels.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Additional\n",
    "* A bit messy, this is where we explore additional potential features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with normalizing transformations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot((class_df['response_similarity'])**3, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df['res_sim_cubed'] = (class_df['response_similarity'])**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.cbrt(class_df['response_a_length']), kde=True)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Cube Root of Response Length (Model A)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.cbrt(class_df['response_b_length']), kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.log(class_df['prompt_length']), kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df['cube_a_length'] = np.cbrt(class_df['response_a_length'])\n",
    "class_df['cube_b_length'] = np.cbrt(class_df['response_b_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((class_df['pr_model_b_win']), kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Creating Response to Prompt Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response to Prompt similarity\n",
    "response_a_similarities = cosine_similarity(response_a_embeddings, prompt_embeddings)\n",
    "response_b_similarities = cosine_similarity(response_b_embeddings, prompt_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_a_similarities = np.delete(response_a_similarities, removed_na, axis=0)\n",
    "response_a_similarities = np.delete(response_a_similarities, removed_na, axis=1)\n",
    "\n",
    "response_b_similarities = np.delete(response_b_similarities, removed_na, axis=0)\n",
    "response_b_similarities = np.delete(response_b_similarities, removed_na, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_a_similarities = np.delete(response_a_similarities, dropped_indices, axis=0)\n",
    "response_a_similarities = np.delete(response_a_similarities, dropped_indices, axis=1)\n",
    "\n",
    "response_b_similarities = np.delete(response_b_similarities, dropped_indices, axis=0)\n",
    "response_b_similarities = np.delete(response_b_similarities, dropped_indices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_a_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop additional na if not removed yet\n",
    "class_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign response to prompt similarities\n",
    "class_df['response_a_prompt_similarity'] = response_a_similarities.diagonal()\n",
    "class_df['response_b_prompt_similarity'] = response_b_similarities.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((class_df['response_a_prompt_similarity'])**3, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((class_df['response_b_prompt_similarity'])**3, kde=True)\n",
    "plt.xlabel('Cosine Similarity of Response B to Prompts Cubed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign transformed response similarities\n",
    "class_df['rpSim_a_cubed'] = (class_df['response_a_prompt_similarity'])**3\n",
    "class_df['rpSim_b_cubed'] = (class_df['response_b_prompt_similarity'])**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Code for Elo\n",
    "* This feature largely goes unused, but we keep to show our work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding ELO (Sonja Code)\n",
    "# Code for ELO rating\n",
    "def calc_elo(ratings, A, B, winner):\n",
    "    RA = ratings[A]\n",
    "    RB = ratings[B]\n",
    "    #w = ratings[winner]\n",
    "\n",
    "    EA = 1.0 / (1.0 + 10.0**((RB - RA)/400.0))\n",
    "    EB = 1.0 / (1.0 + 10.0**((RA - RB)/400.0))\n",
    "\n",
    "    if winner == 'model_a':\n",
    "        SA, SB = 1.0, 0.0\n",
    "    elif winner == 'model_b':\n",
    "        SA, SB = 0.0, 1.0\n",
    "    else:\n",
    "        SA, SB = 0.5, 0.5\n",
    "\n",
    "    ratings[A] = RA + 32.0 * (SA - EA)\n",
    "    ratings[B] = RB + 32.0 * (SB - EB)\n",
    "\n",
    "    return ratings\n",
    "\n",
    "def get_updated_elo(ratings, matches):\n",
    "    num_matches = len(matches)\n",
    "    for i in range(num_matches):\n",
    "        A, B, winner = matches.iloc[i,0], matches.iloc[i,1], matches.iloc[i,2]\n",
    "        ratings = calc_elo(ratings, A, B, winner)\n",
    "    return ratings\n",
    "\n",
    "def make_ELO_list(x):\n",
    "    '''\n",
    "    Should return a len 20 list with the corresponding ratings for each model\n",
    "    '''\n",
    "    matches = x[['model_a', 'model_b', 'winner']]\n",
    "    models_list = ['chatglm-6b', 'oasst-pythia-12b', 'koala-13b', 'vicuna-13b', 'stablelm-tuned-alpha-7b', 'alpaca-13b', 'llama-13b', 'dolly-v2-12b','fastchat-t5-3b', 'gpt-3.5-turbo', 'gpt-4', 'claude-v1', 'RWKV-4-Raven-14B','mpt-7b-chat', 'palm-2', 'claude-instant-v1', 'vicuna-7b', 'wizardlm-13b','gpt4all-13b-snoozy', 'guanaco-33b']\n",
    "    ratings = {key: 1200.0 for key in models_list}\n",
    "    for i in range(5):\n",
    "        ratings = get_updated_elo(ratings, matches)\n",
    "\n",
    "    rankings = ratings.copy()\n",
    "    sorted_items = sorted(ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # value_to_int_map = {key: i + 1 for i, (key, value) in enumerate(sorted_items)}\n",
    "\n",
    "    # for key in value_to_int_map:\n",
    "    #     rankings[key] = value_to_int_map[key]\n",
    "\n",
    "    ELO_list = rankings\n",
    "    return ELO_list\n",
    "    \n",
    "result = make_ELO_list(class_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictedWinnerByElo(df, dict):\n",
    "    \n",
    "    df['model_a_elo'] = df['model_a'].map(dict)\n",
    "    df['model_b_elo'] = df['model_b'].map(dict)\n",
    "\n",
    "    df['elo_difference'] = df['model_a_elo'] - df['model_b_elo']\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = predictedWinnerByElo(class_df, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From experimentation, it was found that elo does not add as much value as BT\n",
    "# We thus add log_bt scores to make our model more similar to a BT model\n",
    "class_df['log_bt_a'] = np.log(class_df['model_a_skill'])\n",
    "class_df['log_bt_b'] = np.log(class_df['model_b_skill'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Identical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifIdentical(se):\n",
    "    if se['response_a'] == se['response_b']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "class_df['identical_indicator'] = class_df[['response_a', 'response_b']].apply(ifIdentical, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Sentiment Analysis\n",
    "* Largely unused, not a valuable feature for our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "# from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_clf = pipeline('sentiment-analysis')\n",
    "# results_a = sentiment_clf(list(class_df['response_a']), max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_b = sentiment_clf(list(class_df['response_b']), max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving sentiment scores for later use\n",
    "# import pickle   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"response_a_sentiment.pickle\", \"wb\") as file:\n",
    "#     pickle.dump(results_a, file)\n",
    "\n",
    "# with open(\"response_b_sentiment.pickle\", \"wb\") as file:\n",
    "#     pickle.dump(results_b, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(results_a)['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_df['response_a_sentiment'] = pd.DataFrame(results_a)['label']\n",
    "# class_df['response_b_sentiment'] = pd.DataFrame(results_b)['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Labels\n",
    "* Assigning clusters as labels to our clf model to be used later as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_matrix = np.stack(class_df['prompt_embedding'].to_numpy())\n",
    "\n",
    "# Clustering embeddings\n",
    "k = 50\n",
    "k_means = KMeans(n_clusters=k,\n",
    "               random_state=42)\n",
    "cluster_labels = k_means.fit_predict(prompt_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df['cluster_labels'] = cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY7E8osYrltb"
   },
   "source": [
    "## Training and Validation for Task A\n",
    "* Here is where we undergo the initial modeling for our model. That is, our training and validation primarily occurs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxnM1PItrqKX"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import RFECV\n",
    "# Yoinking Sonja's K-Fold CV Code\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# gridsearch\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of class in case anything goes wrong\n",
    "train_data = class_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4a-D8fxvOW5"
   },
   "outputs": [],
   "source": [
    "# Drop additional na, if any\n",
    "train_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['cube_a_length', 'cube_b_length', 'log_prompt_length', 'res_sim_cubed', 'log_bt_a', 'log_bt_b', 'hardness_score', 'rpSim_b_cubed', 'rpSim_a_cubed', 'identical_indicator', 'cluster_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHyvG719rtLn"
   },
   "outputs": [],
   "source": [
    "# Pull out main features being used\n",
    "train_data = train_data[['cube_a_length', 'cube_b_length', 'log_prompt_length', \n",
    "              'res_sim_cubed', 'log_bt_a', 'log_bt_b', 'hardness_score', 'rpSim_b_cubed',\n",
    "             'rpSim_a_cubed', 'identical_indicator', 'cluster_labels', 'winner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add Each Dimension of Topic Embedding as Seperate Feature:\n",
    "for i in range(train_topic_embeddings.shape[1]):\n",
    "    train_data[f'topic_dim_{i}'] = train_topic_embeddings[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_CV_errorCLF(X_train, Y_train, folds=10):\n",
    "    '''\n",
    "    Split the training data into `k` subsets.\n",
    "    For each subset,\n",
    "        - Fit a model holding out that subset.\n",
    "        - Compute the MSE on that subset (the validation set).\n",
    "    You should be fitting `k` models in total.\n",
    "    Return a list of `k` RMSEs.\n",
    "\n",
    "    Args:\n",
    "        model: An sklearn model with fit and predict functions.\n",
    "        X_train (DataFrame): Training data.\n",
    "        Y_train (DataFrame): Label.\n",
    "\n",
    "    Return:\n",
    "         A list of `k` Accuracy Scores.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    clf = LogisticRegression(random_state=42,\n",
    "                             solver='saga',\n",
    "                             penalty='l1',\n",
    "                             C=0.23713737056616552,\n",
    "                             max_iter=4000,\n",
    "                            fit_intercept=True)\n",
    "    \n",
    "    kf = KFold(n_splits=folds)\n",
    "    validation_errors = []\n",
    "    average_accuracy = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # Split the data\n",
    "        split_X_train, split_X_valid = X_train[train_idx], X_train[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y_train[train_idx], Y_train[valid_idx]\n",
    "\n",
    "        # Fit the model on the training split\n",
    "        clf.fit(split_X_train, split_Y_train)\n",
    "        split_Y_valid_pred = clf.predict_proba(split_X_valid)\n",
    "        split_Y_train_pred = clf.predict_proba(split_X_train)\n",
    "\n",
    "        # Compute the Accuracy and Log Loss on the validation split\n",
    "        valid_accuracy = clf.score(split_X_valid, split_Y_valid)\n",
    "        train_accuracy = clf.score(split_X_train, split_Y_train)\n",
    "\n",
    "        # target_names = ['class 0', 'class 1', 'class 2', 'class_3']\n",
    "        # print(precision_recall_fscore_support(split_Y_valid, split_Y_valid_pred, average='weighted'))\n",
    "        # Log Loss\n",
    "        # valid_log = log_loss(split_Y_valid, split_Y_valid_pred)\n",
    "        # train_log = log_loss(split_Y_train, split_Y_train_pred)\n",
    "\n",
    "        # # Errors String:\n",
    "        # error = {'Train': {'Accuracy': train_accuracy, 'Log': train_log}, 'Valid': {'Accuracy': valid_accuracy, 'Log': valid_log}}\n",
    "\n",
    "        # validation_errors.append(error)\n",
    "        average_accuracy.append(valid_accuracy)\n",
    "\n",
    "    # feature_strength = clf.coef_\n",
    "\n",
    "    return np.mean(average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalModeling(X_and_y):\n",
    "    \"\"\"\n",
    "    Use clusters as a OHE feature\n",
    "    Basic function for experimentiing with logistic regression\n",
    "    \"\"\"\n",
    "    preprocessor = make_column_transformer(\n",
    "        (OneHotEncoder(), ['cluster_labels']),\n",
    "        remainder = 'passthrough' # this leaves all other columns intact (no transformations done)\n",
    "    )\n",
    "    # y_obs preprocess\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "\n",
    "    cluster_X = X_and_y[['cube_a_length', 'cube_b_length', 'log_prompt_length', \n",
    "          'res_sim_cubed', 'log_bt_a', 'log_bt_b', 'hardness_score', 'rpSim_b_cubed',\n",
    "         'rpSim_a_cubed', 'identical_indicator', 'cluster_labels', 'topic_dim_0', 'topic_dim_1', 'topic_dim_2', 'topic_dim_3',\n",
    "                         'topic_dim_4', 'topic_dim_5', 'topic_dim_6', 'topic_dim_7',\n",
    "                         'topic_dim_8', 'topic_dim_9']]\n",
    "    \n",
    "   \n",
    "    cluster_y = le.fit_transform(X_and_y['winner'])\n",
    "\n",
    "\n",
    "    # Preprocessing\n",
    "    cluster_X_transformed = preprocessor.fit_transform(cluster_X)\n",
    "\n",
    "    # Generate train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cluster_X_transformed, cluster_y, random_state=42)\n",
    "\n",
    "    avg_ac = compute_CV_errorCLF(X_train, y_train, folds=4)\n",
    "\n",
    "    print(f'Valid Avg Accuracy: {avg_ac}')\n",
    "    \n",
    "    return avg_ac\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearchModeling(X_and_y):\n",
    "    \"\"\"\n",
    "    Used to test C Values\n",
    "    \"\"\"\n",
    "    preprocessor = make_column_transformer(\n",
    "        (OneHotEncoder(), ['cluster_labels']),\n",
    "        remainder = 'passthrough' # this leaves all other columns intact (no transformations done)\n",
    "    )\n",
    "    # y_obs preprocess\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "\n",
    "    X_train_grid = X_and_y[['cube_a_length', 'cube_b_length', 'log_prompt_length', \n",
    "          'res_sim_cubed', 'log_bt_a', 'log_bt_b', 'hardness_score', 'rpSim_b_cubed',\n",
    "         'rpSim_a_cubed', 'identical_indicator', 'cluster_labels', 'topic_dim_0', 'topic_dim_1', 'topic_dim_2', 'topic_dim_3',\n",
    "                         'topic_dim_4', 'topic_dim_5', 'topic_dim_6', 'topic_dim_7',\n",
    "                         'topic_dim_8', 'topic_dim_9']]\n",
    "    \n",
    "   \n",
    "    Y_train_grid = le.fit_transform(X_and_y['winner'])\n",
    "\n",
    "\n",
    "    # Preprocessing\n",
    "    X_train_grid = preprocessor.fit_transform(X_train_grid)\n",
    "\n",
    "    # Define a parameter grid to be used in grid search cv\n",
    "    param_grid = {'C': np.logspace(-5, 2, 9), 'penalty': ['l1','l2']}\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # Define Logistic Regression model\n",
    "    clf = LogisticRegression(random_state=42,\n",
    "                             solver='saga',\n",
    "                             penalty='l2',\n",
    "                             max_iter=4000,\n",
    "                            fit_intercept=True)\n",
    "\n",
    "    # define grid search \n",
    "    search = GridSearchCV(clf,\n",
    "                         param_grid=param_grid,\n",
    "                         scoring='accuracy',\n",
    "                         cv=cv,\n",
    "                         n_jobs=-1) # enables paralellism through -1\n",
    "   \n",
    "\n",
    "    search.fit(X_train_grid, Y_train_grid)\n",
    "\n",
    "    #print best params and score\n",
    "    print(search.best_params_, search.best_score_)\n",
    "    \n",
    "    return search.best_score_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the accuracies attained from running normal modeling, aka our baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_accuracy_train = normalModeling(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determined optimal C:0.23713737056616552, penalty: l1\n",
    "# best_grid_score = gridSearchModeling(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with Gradient Boosted Decision Trees\n",
    "* Largely kept in to illustrate that it has no performance gains over logistic regression for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalModelingGradient(X_and_y):\n",
    "    \"\"\"\n",
    "    Use clusters as a OHE feature\n",
    "    \"\"\"\n",
    "    preprocessor = make_column_transformer(\n",
    "        (OneHotEncoder(), ['cluster_labels']),\n",
    "        remainder = 'passthrough' # this leaves all other columns intact (no transformations done)\n",
    "    )\n",
    "    # y_obs preprocess\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "\n",
    "    cluster_X = X_and_y[['cube_a_length', 'cube_b_length', 'log_prompt_length', \n",
    "          'res_sim_cubed', 'log_bt_a', 'log_bt_b', 'hardness_score', 'rpSim_b_cubed',\n",
    "         'rpSim_a_cubed', 'identical_indicator', 'cluster_labels', 'topic_dim_0', 'topic_dim_1', 'topic_dim_2', 'topic_dim_3',\n",
    "                         'topic_dim_4', 'topic_dim_5', 'topic_dim_6', 'topic_dim_7',\n",
    "                         'topic_dim_8', 'topic_dim_9']]\n",
    "    \n",
    "   \n",
    "    cluster_y = le.fit_transform(X_and_y['winner'])\n",
    "\n",
    "\n",
    "    # Preprocessing\n",
    "    cluster_X_transformed = preprocessor.fit_transform(cluster_X)\n",
    "\n",
    "    # Generate train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cluster_X_transformed, cluster_y, random_state=42)\n",
    "\n",
    "    avg_ac = compute_CV_errorGradient(X_train, y_train, folds=10)\n",
    "\n",
    "    print(f'Valid Avg Accuracy: {avg_ac}')\n",
    "    \n",
    "    return avg_ac\n",
    "\n",
    "np.random.seed(42)\n",
    "def compute_CV_errorGradient(X_train, Y_train, folds=10):\n",
    "    '''\n",
    "    Split the training data into `k` subsets.\n",
    "    For each subset,\n",
    "        - Fit a model holding out that subset.\n",
    "        - Compute the MSE on that subset (the validation set).\n",
    "    You should be fitting `k` models in total.\n",
    "    Return a list of `k` RMSEs.\n",
    "\n",
    "    Args:\n",
    "        model: An sklearn model with fit and predict functions.\n",
    "        X_train (DataFrame): Training data.\n",
    "        Y_train (DataFrame): Label.\n",
    "\n",
    "    Return:\n",
    "         A list of `k` Accuracy Scores.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    clf = GradientBoostingClassifier(n_estimators=100, \n",
    "                                     learning_rate=1.0,\n",
    "                                      max_depth=1, \n",
    "                                     random_state=42)\n",
    "    \n",
    "    kf = KFold(n_splits=folds)\n",
    "    validation_errors = []\n",
    "    average_accuracy = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # Split the data\n",
    "        split_X_train, split_X_valid = X_train[train_idx], X_train[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y_train[train_idx], Y_train[valid_idx]\n",
    "\n",
    "        # Fit the model on the training split\n",
    "        clf.fit(split_X_train, split_Y_train)\n",
    "        split_Y_valid_pred = clf.predict_proba(split_X_valid)\n",
    "\n",
    "        # Compute the Accuracy and Log Loss on the validation split\n",
    "        valid_accuracy = clf.score(split_X_valid, split_Y_valid)\n",
    "\n",
    "        # target_names = ['class 0', 'class 1', 'class 2', 'class_3']\n",
    "        # print(precision_recall_fscore_support(split_Y_valid, split_Y_valid_pred, average='weighted'))\n",
    "        # Log Loss\n",
    "        # valid_log = log_loss(split_Y_valid, split_Y_valid_pred)\n",
    "        # train_log = log_loss(split_Y_train, split_Y_train_pred)\n",
    "\n",
    "        # # Errors String:\n",
    "        # error = {'Train': {'Accuracy': train_accuracy, 'Log': train_log}, 'Valid': {'Accuracy': valid_accuracy, 'Log': valid_log}}\n",
    "\n",
    "        # validation_errors.append(error)\n",
    "        average_accuracy.append(valid_accuracy)\n",
    "\n",
    "    # feature_strength = clf.coef_\n",
    "\n",
    "    return np.mean(average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_accuracies = normalModelingGradient(train_data)"
   ]
  },
  {
   "attachments": {
    "efbf4a8f-b9e2-4cff-923c-72d0dca56a1f.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Expected Accuracy:\n",
    "- ![image.png](attachment:efbf4a8f-b9e2-4cff-923c-72d0dca56a1f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AG97QECg1vWF"
   },
   "source": [
    "## Classifier Test\n",
    "* This is where we run our classifier test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KB2tuW1Y3Xah"
   },
   "outputs": [],
   "source": [
    "# When Sonja and I were working seperately, this is where I consolidated our scores for\n",
    "# Experimentation purposes\n",
    "# Getting hardness scores from test csv\n",
    "predictions = pd.read_csv('output_final_b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbwaFhi8xn6l"
   },
   "outputs": [],
   "source": [
    "# Prepping Test Predictions Raw Dataset\n",
    "test_class_df = test_prompts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairing a prompt embedding with cluster labels for the purpose of \n",
    "# Assigning cluster labels to the test data set\n",
    "prompt_clusters = class_df[['prompt_embedding', 'cluster_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering Code via Sonja\n",
    "# Assign test data to prompt clusters\n",
    "\n",
    "# get cluster centroids (using df since that's what we used for the clustering)\n",
    "df_sorted = prompt_clusters.sort_values(by='cluster_labels')\n",
    "df_cen = df_sorted.groupby('cluster_labels')['prompt_embedding'].mean().rename('prompt_centroids')\n",
    "\n",
    "# assigns an embedding to a cluster by smallest Euclidean distance\n",
    "def assign_to_cluster(x):\n",
    "  dist = []\n",
    "  for i in range(len(df_cen)):\n",
    "    distance = np.linalg.norm(x - df_cen.iloc[i])\n",
    "    dist.append(distance)\n",
    "  return np.argmin(dist)\n",
    "\n",
    "# assign\n",
    "test_class_df['prompt_embeddings'] = list(test_prompt_embeddings)\n",
    "test_class_df['cluster_labels'] = test_class_df['prompt_embeddings'].apply(lambda x: assign_to_cluster(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Identical Indicator Assignment function to accomodate for differently named columns in test set\n",
    "def ifIdenticalTest(se):\n",
    "    if se['model_a_response'] == se['model_b_response']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QY-OHhiR0KE0"
   },
   "outputs": [],
   "source": [
    "# Crafting a preprocessing function to return a transformed X_test\n",
    "def classPreprocess(df, test_reduced_embeddings, preds, ra_embed, rb_embed, tp_embed): # preds is temporary\n",
    "    # ignore warnings\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    # Extract prompts and prompt lengths\n",
    "    df[\"prompt_length\"] = df[\"prompt\"].str.len()\n",
    "    df[\"response_a_length\"] = df[\"model_a_response\"].str.len()\n",
    "    df[\"response_b_length\"] = df[\"model_b_response\"].str.len()\n",
    "    df['response_length_difference'] = np.absolute(df['response_a_length'] - df['response_b_length'])\n",
    "    \n",
    "    # assign BT scores\n",
    "    df = btAllocate(df, bt_model_skill_levels.to_dict())\n",
    "\n",
    "    # Create Indicator Variables\n",
    "    df['identical_indicator'] = df[['model_a_response', 'model_b_response']].apply(ifIdenticalTest, axis=1)\n",
    "\n",
    "    # Generate Similarity Scores \n",
    "    ra_similarities = cosine_similarity(ra_embed, tp_embed)\n",
    "    rb_similarities = cosine_similarity(rb_embed, tp_embed)\n",
    "    r_similarities = cosine_similarity(ra_embed, rb_embed)\n",
    "        \n",
    "    # Add Hardness Scores from Sonja's Predictions\n",
    "    df['hardness_score'] = preds['hardness_score']\n",
    "    \n",
    "    # Fixing skew with transforms\n",
    "    df['log_prompt_length'] = np.log(df['prompt_length'])\n",
    "    df['cube_a_length'] = np.cbrt(df['response_a_length'])\n",
    "    df['cube_b_length'] = np.cbrt(df['response_b_length'])\n",
    "    df['res_sim_cubed'] = (r_similarities.diagonal())**3\n",
    "    df['log_bt_a'] = np.log(df['model_a_skill'])\n",
    "    df['log_bt_b'] = np.log(df['model_b_skill'])\n",
    "    df['rpSim_a_cubed'] = (ra_similarities.diagonal())**3\n",
    "    df['rpSim_b_cubed'] = (rb_similarities.diagonal())**3\n",
    "    \n",
    "    preprocessor = make_column_transformer(\n",
    "        (OneHotEncoder(), ['cluster_labels']),\n",
    "        remainder = 'passthrough' # this leaves all other columns intact (no transformations done)\n",
    "    )\n",
    "   \n",
    "    \n",
    "    cluster_X = df[['cube_a_length', 'cube_b_length', 'log_prompt_length', \n",
    "          'res_sim_cubed', 'log_bt_a', 'log_bt_b', 'hardness_score', 'rpSim_b_cubed',\n",
    "         'rpSim_a_cubed', 'identical_indicator', 'cluster_labels']]\n",
    "    \n",
    "    # Add Test Topic Embeddings\n",
    "    for i in range(test_reduced_embeddings.shape[1]):\n",
    "        cluster_X[f'topic_dim_{i}'] = test_reduced_embeddings[:, i]\n",
    "    print(cluster_X.shape)\n",
    "    # Preprocessing\n",
    "    X_test = preprocessor.fit_transform(cluster_X)\n",
    "\n",
    "    \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_X_test = classPreprocess(test_class_df, test_topic_embeddings, predictions, test_response_a_embeddings,\n",
    "                             test_response_b_embeddings, test_prompt_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions\n",
    "def predictLabels(X_and_y, true_X_test):\n",
    "    \"\"\"\n",
    "    Generates predictions\n",
    "    and returns confusion matrix\n",
    "    \"\"\"\n",
    "    preprocessor = make_column_transformer(\n",
    "        (OneHotEncoder(), ['cluster_labels']),\n",
    "        remainder = 'passthrough' # this leaves all other columns intact (no transformations done)\n",
    "    )\n",
    "    # y_obs preprocess\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "\n",
    "    X_train_local = X_and_y[['cube_a_length', 'cube_b_length', 'log_prompt_length', \n",
    "          'res_sim_cubed', 'log_bt_a', 'log_bt_b', 'hardness_score', 'rpSim_b_cubed',\n",
    "         'rpSim_a_cubed', 'identical_indicator', 'cluster_labels', 'topic_dim_0', 'topic_dim_1', 'topic_dim_2', 'topic_dim_3',\n",
    "                         'topic_dim_4', 'topic_dim_5', 'topic_dim_6', 'topic_dim_7',\n",
    "                         'topic_dim_8', 'topic_dim_9']]\n",
    "\n",
    "    y_train_local = le.fit_transform(X_and_y['winner'])\n",
    "\n",
    "\n",
    "    # Preprocessing\n",
    "    X_train_transformed_local = preprocessor.fit_transform(X_train_local)\n",
    "\n",
    "    clf = LogisticRegression(random_state=42,\n",
    "                             solver='saga',\n",
    "                             penalty='l1',\n",
    "                             C=0.23713737056616552,\n",
    "                             max_iter=4000,\n",
    "                            fit_intercept=True)\n",
    "\n",
    "    clf.fit(X_train_transformed_local, y_train_local)\n",
    "\n",
    "    class_predictions = clf.predict(true_X_test)\n",
    "    train_predictions = clf.predict(X_train_transformed_local)\n",
    "    conf_matrix = confusion_matrix(y_train_local, train_predictions)\n",
    "    \n",
    "    return class_predictions, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Predictions\n",
    "* Generate predictions, assign them, and then create a confusion matrix\n",
    "* Mainly used when Sonja and I were working on seperate notebooks to consolidate our answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_predictions, conf_matrix = predictLabels(train_data, true_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign class predictions to predictions df (relic from working seperately)\n",
    "# predictions['winner'] = class_predictions\n",
    "# predictions['winner'] = predictions['winner'].map({0:'model_a', 1:'model_b',2:'tie',3:'tie (bothbad)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "# predictions.to_csv('output_final_b_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Model_A', 'Model_B', 'Tie', 'Tie (BothBad)']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
    "# cmap = plt.get_cmap('Blues')\n",
    "# plt.set_cmap(cmap)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Winner')\n",
    "plt.ylabel('True Winner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mT1sEOImAWB"
   },
   "source": [
    "# **Task B**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFRuNXZzkdEH"
   },
   "source": [
    "# Some feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vAb1zEB2gMDv"
   },
   "outputs": [],
   "source": [
    "# Some data cleaning and feature engineering\n",
    "\n",
    "# Extract topics from salvagable null rows:\n",
    "score_regex = r'\\\"score_value\\\":\\s(\\d)+'\n",
    "\n",
    "# Salvagable raw choices used above in topic_extraction\n",
    "salvagable_raw_choices = salvagable_null_rows.loc[:,'openai_scores_raw_choices_nested'].astype('str')\n",
    "salvagable_raw_scores = salvagable_raw_choices.str.findall(pat=score_regex)\n",
    "\n",
    "# Converting strings to ints then taking means\n",
    "for index in salvagable_raw_scores.index:\n",
    "    salvagable_raw_scores[index] = [int(item) for item in salvagable_raw_scores[index]]\n",
    "    salvagable_raw_scores[index] = np.mean(salvagable_raw_scores[index])\n",
    "\n",
    "# Save average hardness scores as series\n",
    "salvagable_raw_scores.name = 'avg_hardness_score'\n",
    "salvagable_null_rows['avg_hardness_score'] = salvagable_raw_scores\n",
    "\n",
    "# Get average hardness scores of main data frame\n",
    "topic_and_hardness['avg_hardness_score'] = (topic_and_hardness['score_value_1'] + topic_and_hardness['score_value_2'] + topic_and_hardness['score_value_3']) / 3\n",
    "\n",
    "# Copy t & h into new df to avoid colab issues\n",
    "topic_and_hardness_b = pd.concat([topic_and_hardness, salvagable_null_rows])\n",
    "topic_and_hardness_b = topic_and_hardness_b.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Nl9VQ2nXNpv"
   },
   "outputs": [],
   "source": [
    "# Get prompt features related to length\n",
    "topic_and_hardness_b[\"prompt_length\"] = topic_and_hardness_b[\"prompt\"].str.len()\n",
    "topic_and_hardness_b[\"Log prompt_length\"] = topic_and_hardness_b[\"prompt_length\"].apply(lambda x: np.log(x))\n",
    "\n",
    "# Prompt word counts\n",
    "topic_and_hardness_b['prompt_wc'] = topic_and_hardness_b['prompt'].str.split().str.len()\n",
    "topic_and_hardness_b[\"Log prompt_wc\"] = topic_and_hardness_b[\"prompt_wc\"].apply(lambda x: np.log(x))\n",
    "\n",
    "# response lengths\n",
    "df_response_length = df[['question_id', \"model_a_response_length\", \"model_b_response_length\"]]\n",
    "\n",
    "topic_and_hardness_b = pd.merge(topic_and_hardness_b, df_response_length, on='question_id', how='left')\n",
    "topic_and_hardness_b[\"Log model_a_response_length\"] = topic_and_hardness_b[\"model_a_response_length\"].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDK-3X3rqAJy"
   },
   "source": [
    "## K-means clustering for prompt embeddings\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1kIpZBop_cf"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "\n",
    "# Gonna do k-means on the non-duplicate rows\n",
    "prompt_embeddings_no_dupes = np.delete(prompt_embeddings, dropped_indices, axis=0)\n",
    "\n",
    "# save prompt embeddings to 2D matrix for k-means\n",
    "matrix = np.stack(df['prompt_embedding'].to_numpy())\n",
    "\n",
    "# Clustering embeddings\n",
    "k = 50\n",
    "k_means = KMeans(n_clusters=k,\n",
    "               random_state=42)\n",
    "cluster_labels = k_means.fit_predict(matrix)\n",
    "\n",
    "# save cluster labels as series\n",
    "df['prompt_embedding_cluster'] = cluster_labels\n",
    "df2 = df[['question_id','prompt_embedding','prompt_embedding_cluster']]\n",
    "\n",
    "# merge cluster labels with t & h\n",
    "topic_and_hardness_b = pd.merge(topic_and_hardness_b, df2, on='question_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e02cB-BbGiek"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKP8ND_YGh2v"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot-encoding function\n",
    "def ohe_wall_material(data, label):\n",
    "    \"\"\"\n",
    "    One-hot-encodes a column.\n",
    "    \"\"\"\n",
    "    new_data = data.copy(deep=True)\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    ohe = encoder.fit_transform(new_data[[label]])\n",
    "\n",
    "    encoded_df = pd.DataFrame(ohe, columns=encoder.categories_[0])\n",
    "\n",
    "    encoded_df.index = new_data.index\n",
    "\n",
    "    new_data = pd.concat([new_data, encoded_df], axis=1)\n",
    "\n",
    "    # Rename columns\n",
    "    original_columns = new_data[label].unique()\n",
    "    rename_dict = {col: label + '_' + str(col) for col in original_columns}\n",
    "    new_data = new_data.rename(columns=rename_dict)\n",
    "\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwMR8yM3YVaG"
   },
   "outputs": [],
   "source": [
    "# OHE the prompt embedding cluster labels\n",
    "topic_and_hardness_b = ohe_wall_material(topic_and_hardness_b, 'prompt_embedding_cluster')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX-T2254Mhb8"
   },
   "source": [
    "### More EDA for random features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzXhCT7yN5q1"
   },
   "outputs": [],
   "source": [
    "# Get the number of question marks?\n",
    "topic_and_hardness_b['num_?'] = topic_and_hardness_b['prompt'].str.count(r'\\?')\n",
    "\n",
    "# Whether or not prompt contains one or more question marks\n",
    "topic_and_hardness_b[\"contain_?\"] = topic_and_hardness_b['num_?'].map(lambda x: '1' if x > 0 else '0')\n",
    "\n",
    "# OHE\n",
    "topic_and_hardness_b = ohe_wall_material(topic_and_hardness_b, 'contain_?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tswgBxqzsqqN"
   },
   "source": [
    "# Getting prompt sentiments with the DistilBERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBtK7U9blCmZ"
   },
   "source": [
    "This took about 40 mins to run so I will provide the csv file with the data instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTEOkSn-sMqK"
   },
   "outputs": [],
   "source": [
    "#from transformers import pipeline\n",
    "#model_checkpoint = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "#model_checkpoint = \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "\n",
    "# Load the model\n",
    "#sentiment_analysis = pipeline(\"sentiment-analysis\", model=model_checkpoint, truncation=True)\n",
    "\n",
    "def get_sentiment_abs(x):\n",
    "  sentiment = sentiment_analysis(x)\n",
    "  score = sentiment[0]['score']\n",
    "  if sentiment[0]['label'] == 'negative':\n",
    "    score *= -1.0\n",
    "  return score\n",
    "\n",
    "#topic_and_hardness_b['sentiment_abs'] = topic_and_hardness_b['prompt'].apply(lambda x: get_sentiment_abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJUMTjo63Ohj"
   },
   "outputs": [],
   "source": [
    "#df_sentiment = topic_and_hardness_b[['question_id','prompt','sentiment_abs']]\n",
    "\n",
    "# Save to CSV\n",
    "#df_sentiment.to_csv('sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plNQgmRGB6b-"
   },
   "outputs": [],
   "source": [
    "# read sentiment csv\n",
    "\n",
    "df_read_sentiment = pd.read_csv('sentiment_raw_pos_neg.csv', usecols=['question_id', 'sentiment_squared'])\n",
    "\n",
    "topic_and_hardness_b = pd.merge(topic_and_hardness_b, df_read_sentiment, on='question_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJq2Qlbr0weU"
   },
   "outputs": [],
   "source": [
    "# Get absolute value of sentiment\n",
    "topic_and_hardness_b['sentiment_abs'] = topic_and_hardness_b['sentiment_squared'].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "j19YHsyxalyk",
    "outputId": "cbcac3e8-da66-46ea-9bdb-8e49db987f5b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(topic_and_hardness_b['sentiment_abs'], kde=True)\n",
    "plt.title('Distribution of Absolute Sentiment Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBz_ZgHnyaQH"
   },
   "source": [
    "# Subjectivity with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoLISK0pydJO"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_subjectivity(x):\n",
    "  blob = TextBlob(x)\n",
    "  return blob.sentiment.subjectivity\n",
    "\n",
    "topic_and_hardness_b['prompt_subjectivity'] = topic_and_hardness_b['prompt'].apply(lambda x: get_subjectivity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "DD-d9hdpY_XV",
    "outputId": "63d88e85-23b4-46ea-e46f-4764292ee59f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(topic_and_hardness_b['prompt_subjectivity'], kde=True)\n",
    "plt.title('Distribution of Prompt Subjectivity Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "16bGw5zUZKp_",
    "outputId": "1c528ca2-35b2-4eb3-a434-b6650399d0a4"
   },
   "outputs": [],
   "source": [
    "topic_and_hardness_b['prompt_subjectivity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4fzy6ldz3fR"
   },
   "outputs": [],
   "source": [
    "df_subjectivity = topic_and_hardness_b[['question_id','prompt','prompt_subjectivity']]\n",
    "\n",
    "# Save to CSV\n",
    "df_subjectivity.to_csv('subjectivity.csv', float_format='%.10f', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-sYg4hdMEXF"
   },
   "source": [
    "# Topic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2ugNUIpaAnD"
   },
   "outputs": [],
   "source": [
    "# Store each of the 10 topic embedding dimensions as its own column\n",
    "for i in range(train_topic_embeddings.shape[1]):\n",
    "    topic_and_hardness_b[f'topic_dim_{i}'] = train_topic_embeddings[:, i]\n",
    "\n",
    "topic_and_hardness_b[\"topic_embedding\"] = list(train_topic_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdTs_Pv45iG1"
   },
   "source": [
    "# Turning model A and B embeddings into features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fy7LIxQEgvlY"
   },
   "outputs": [],
   "source": [
    "# Making model A response embeddings a feature\n",
    "\n",
    "topic_and_hardness_b = pd.merge(topic_and_hardness_b, df[['question_id', \"model_a_response_embedding\"]], on='question_id', how='left')\n",
    "array_2d = np.stack(topic_and_hardness_b[\"model_a_response_embedding\"].values)\n",
    "\n",
    "df_expanded = pd.DataFrame(array_2d)\n",
    "\n",
    "df_expanded.columns = [f'model_a_dim_{i}' for i in range(256)]\n",
    "\n",
    "original_index = topic_and_hardness_b.index\n",
    "topic_and_hardness_b = pd.concat([topic_and_hardness_b.reset_index(drop=True), df_expanded.reset_index(drop=True)], axis=1)\n",
    "topic_and_hardness_b.index = original_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InGVk7KROvdG"
   },
   "outputs": [],
   "source": [
    "# Do the same for Model B\n",
    "topic_and_hardness_b = pd.merge(topic_and_hardness_b, df[['question_id', \"model_b_response_embedding\"]], on='question_id', how='left')\n",
    "array_2d = np.stack(topic_and_hardness_b[\"model_b_response_embedding\"].values)\n",
    "\n",
    "df_expanded = pd.DataFrame(array_2d)\n",
    "\n",
    "df_expanded.columns = [f'model_b_dim_{i}' for i in range(256)]\n",
    "\n",
    "original_index = topic_and_hardness_b.index\n",
    "topic_and_hardness_b = pd.concat([topic_and_hardness_b.reset_index(drop=True), df_expanded.reset_index(drop=True)], axis=1)\n",
    "topic_and_hardness_b.index = original_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvBLxqHzJ_W5"
   },
   "source": [
    "## Looking at Correlations of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "3nnaemS2J-0y",
    "outputId": "4098f0a8-f28e-4ac6-9e41-89e5eef71a04"
   },
   "outputs": [],
   "source": [
    "dfc = topic_and_hardness_b[['avg_hardness_score', 'Log prompt_length', 'Log prompt_wc', 'contain_?', \"model_a_response_length\", 'sentiment_abs', 'prompt_subjectivity']]#,'problem solving']]\n",
    "\n",
    "corr_df = dfc.corr()\n",
    "\n",
    "sns.heatmap(corr_df, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "\n",
    "plt.title(\"Pearson Pairwise Correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Y06CYdY726-"
   },
   "source": [
    "# Building OLS model (no regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMeTjlzdmN9d"
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "# RMSE loss function\n",
    "def rmse(predicted, actual):\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))\n",
    "\n",
    "# training data splitting function\n",
    "def train_val_split(data, split=0.8):\n",
    "    data_len = data.shape[0]\n",
    "    shuffled_indices = np.random.permutation(data_len)\n",
    "    train_ind = shuffled_indices[:int(split*data_len)]\n",
    "    validation_ind = shuffled_indices[int(split*data_len):]\n",
    "    train = data.iloc[train_ind]\n",
    "    validation = data.iloc[validation_ind]\n",
    "\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTLFlwFdceEg",
    "outputId": "7bca70f1-e886-4dd5-a2a0-0511d2716069"
   },
   "outputs": [],
   "source": [
    "# Hand-pick features here! Using prompt embedding cluster, log prompt length,\n",
    "# topic embeddings, and model a response embeddings\n",
    "\n",
    "# Split training data\n",
    "train, validation = train_val_split(topic_and_hardness_b, 0.99)\n",
    "\n",
    "PE_columns = train['prompt_embedding_cluster'].unique()\n",
    "PE_columns = ['prompt_embedding_cluster_' + str(num) for num in PE_columns]\n",
    "\n",
    "PE_columns.append('Log prompt_length')\n",
    "\n",
    "T_columns = ['topic_dim_' + str(num) for num in range(10)]\n",
    "PE_columns.extend(T_columns)\n",
    "\n",
    "RA_columns = ['model_a_dim_' + str(num) for num in range(256)]\n",
    "PE_columns.extend(RA_columns)\n",
    "\n",
    "RB_columns = ['model_b_dim_' + str(num) for num in range(256)]\n",
    "\n",
    "features = PE_columns\n",
    "\n",
    "print(\"Features chosen for LR:\\n\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAuSV3OYcry5"
   },
   "outputs": [],
   "source": [
    "# Instantiate LR model\n",
    "np.random.seed(4242)\n",
    "\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "\n",
    "# get training data\n",
    "X_train = train[features]\n",
    "Y_train = train[\"avg_hardness_score\"]\n",
    "\n",
    "# get validation data\n",
    "X_valid = validation[PE_columns]\n",
    "Y_valid = validation[\"avg_hardness_score\"]\n",
    "\n",
    "# Fit training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict training X\n",
    "Y_fitted = model.predict(X_train)\n",
    "\n",
    "# Predict validation data\n",
    "Y_predicted = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 995
    },
    "id": "FuBpU-Ldd1JN",
    "outputId": "7f112e21-504a-472c-ff95-cb03366fb19c"
   },
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "\n",
    "print(\"RMSE for training data: \", rmse(Y_train, Y_fitted))\n",
    "print(\"RMSE for validation data: \", rmse(Y_valid, Y_predicted))\n",
    "\n",
    "Y_predicted_rounded = np.round(Y_predicted).astype(int)\n",
    "print(\"RMSE for rounded validation data: \", rmse(Y_valid, Y_predicted_rounded))\n",
    "print()\n",
    "\n",
    "Y_fitted_rounded = np.round(Y_fitted).astype(int)\n",
    "Y_fitted_s = pd.Series(Y_fitted_rounded.reshape(-1))\n",
    "print(\"Rounded fitted Y data:\\n\")\n",
    "print(Y_fitted_s.value_counts())\n",
    "\n",
    "print()\n",
    "Y_predicted_rounded_s = pd.Series(Y_predicted_rounded.reshape(-1))\n",
    "print(\"Rounded predicted Y data:\\n\")\n",
    "print(Y_predicted_rounded_s.value_counts())\n",
    "\n",
    "# Get coefficients\n",
    "#print(\"Coefficients:\", model.coef_)\n",
    "#print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "# Print coefficients with features names in descending order of magnitude\n",
    "coef_df = pd.DataFrame(model.coef_.reshape(-1), index=X_train.columns)\n",
    "coef_df.rename(columns={0: 'coefficient'}, inplace=True)\n",
    "coef_df_sorted = coef_df.sort_values(by = 'coefficient', key=abs, ascending=False)\n",
    "\n",
    "print()\n",
    "print(\"Coefficients, sorted in descending order of abs:\\n\")\n",
    "coef_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5UJiOsW8H2R"
   },
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wa6KeXrpmFZ7",
    "outputId": "b2700ebb-a3f1-434e-de81-0665c2302f1c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "np.random.seed(4242)\n",
    "\n",
    "# CV function\n",
    "def compute_CV_error(X_train, Y_train, folds=10):\n",
    "    model = lm.LinearRegression(fit_intercept=True)\n",
    "    kf = KFold(n_splits=folds)\n",
    "    validation_errors = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # Split the data\n",
    "        split_X_train, split_X_valid = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y_train.iloc[train_idx], Y_train.iloc[valid_idx]\n",
    "\n",
    "        # Fit the model on the training split\n",
    "        model.fit(split_X_train, split_Y_train)\n",
    "        split_Y_valid_pred = model.predict(split_X_valid)\n",
    "\n",
    "        # Compute the RMSE on the validation split\n",
    "        error = rmse(split_Y_valid_pred, split_Y_valid)\n",
    "\n",
    "        validation_errors.append(error)\n",
    "\n",
    "    return validation_errors\n",
    "\n",
    "cv = compute_CV_error(X_train, Y_train, folds=4)\n",
    "#print(f\"4-fold cross validation RMSE errors: {cv}\")\n",
    "avg_cv = np.mean(cv)\n",
    "print(\"Avg 4-fold CV RMSE: \", avg_cv)\n",
    "std_cv = np.std(cv)\n",
    "print(\"Std: \", std_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaUO9ll-u-Fb"
   },
   "source": [
    "## Look at topics of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vylwFbWsu8_Z"
   },
   "outputs": [],
   "source": [
    "#print(topic_and_hardness_b[topic_and_hardness_b['prompt_embedding_cluster'] == 31].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyylFzNq3EIe"
   },
   "source": [
    "## Cleaning up test data + categorizing prompt embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKdeLmmmEJ41"
   },
   "outputs": [],
   "source": [
    "# Get features for test data\n",
    "\n",
    "# prompt length\n",
    "df_test[\"prompt_length\"] = df_test[\"prompt\"].str.len()\n",
    "df_test[\"Log prompt_length\"] = df_test[\"prompt_length\"].apply(lambda x: np.log(x))\n",
    "\n",
    "# prompt wc\n",
    "df_test['prompt_wc'] = df_test['prompt'].str.split().str.len()\n",
    "df_test[\"Log prompt_wc\"] = df_test[\"prompt_wc\"].apply(lambda x: np.log(x))\n",
    "\n",
    "# question marks\n",
    "df_test['num_?'] = df_test['prompt'].str.count(r'\\?')\n",
    "df_test[\"contain_?\"] = df_test['num_?'].map(lambda x: '1' if x > 0 else '0')\n",
    "\n",
    "# model a response length\n",
    "test_prompts[\"model_a_response_length\"] = test_prompts[\"model_a_response\"].str.len()\n",
    "df_test = pd.concat([df_test.reset_index(drop=True), test_prompts[\"model_a_response_length\"].reset_index(drop=True)], axis=1)\n",
    "df_test[\"Log model_a_response_length\"] = df_test[\"model_a_response_length\"].apply(lambda x: np.log(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YLQnb_VqTOC"
   },
   "outputs": [],
   "source": [
    "# Get model A embeddings as feature\n",
    "df_test[\"model_a_response_embedding\"] = list(test_response_a_embeddings)\n",
    "\n",
    "array_2d_test = np.stack(df_test[\"model_a_response_embedding\"].values)\n",
    "\n",
    "df_expanded_test = pd.DataFrame(array_2d_test)\n",
    "\n",
    "df_expanded_test.columns = [f'model_a_dim_{i}' for i in range(256)]\n",
    "\n",
    "original_index_test = df_test.index\n",
    "df_test = pd.concat([df_test.reset_index(drop=True), df_expanded_test.reset_index(drop=True)], axis=1)\n",
    "df_test.index = original_index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVmpM5J1PDCN"
   },
   "outputs": [],
   "source": [
    "# Get model B embeddings as feature\n",
    "df_test[\"model_b_response_embedding\"] = list(test_response_b_embeddings)\n",
    "\n",
    "array_2d_test = np.stack(df_test[\"model_b_response_embedding\"].values)\n",
    "\n",
    "df_expanded_test = pd.DataFrame(array_2d_test)\n",
    "\n",
    "df_expanded_test.columns = [f'model_b_dim_{i}' for i in range(256)]\n",
    "\n",
    "original_index_test = df_test.index\n",
    "df_test = pd.concat([df_test.reset_index(drop=True), df_expanded_test.reset_index(drop=True)], axis=1)\n",
    "df_test.index = original_index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PohdkkVu0nFr"
   },
   "outputs": [],
   "source": [
    "# Assign test data to prompt clusters\n",
    "\n",
    "# get cluster centroids (using df since that's what we used for the clustering)\n",
    "df_sorted = df.sort_values(by='prompt_embedding_cluster')\n",
    "df_cen = df_sorted.groupby('prompt_embedding_cluster')['prompt_embedding'].mean().rename('prompt_centroids')\n",
    "\n",
    "# assigns an embedding to a cluster by smallest Euclidean distance\n",
    "def assign_to_cluster(x):\n",
    "  dist = []\n",
    "  for i in range(len(df_cen)):\n",
    "    distance = np.linalg.norm(x - df_cen.iloc[i])\n",
    "    dist.append(distance)\n",
    "  return np.argmin(dist)\n",
    "\n",
    "# assign\n",
    "df_test['prompt_embeddings'] = list(test_prompt_embeddings)\n",
    "df_test['prompt_embedding_cluster'] = df_test['prompt_embeddings'].apply(lambda x: assign_to_cluster(x))\n",
    "\n",
    "# OHE the test prompt cluster labels\n",
    "df_test = ohe_wall_material(df_test, 'prompt_embedding_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSiQqJM2jkm3"
   },
   "outputs": [],
   "source": [
    "# Do the same for the topic embeddings\n",
    "\n",
    "for i in range(test_topic_embeddings.shape[1]):\n",
    "    df_test[f'topic_dim_{i}'] = test_topic_embeddings[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5Gq2-56_NYI"
   },
   "outputs": [],
   "source": [
    "# Get sentiment for test data if we decide to use sentiments\n",
    "#df_test['sentiment_abs'] = df_test['prompt'].apply(lambda x: get_sentiment_abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcb4SlkvwIQd"
   },
   "source": [
    "# Predicting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4qZBwx4umM4",
    "outputId": "f467a76d-60ed-48d4-c368-7397b37061b2"
   },
   "outputs": [],
   "source": [
    "# Predict test data\n",
    "\n",
    "X_test = df_test[features]\n",
    "Y_test = model.predict(X_test)\n",
    "\n",
    "# Round to get integer data\n",
    "Y_test_rounded = np.round(Y_test).astype(int)\n",
    "\n",
    "my_series = pd.Series(Y_test_rounded.reshape(-1))\n",
    "print(\"Predict rounded Y data:\\n\")\n",
    "print(my_series.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRzVy3bC4PNt"
   },
   "source": [
    "# Write to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFZ-C7y44OBW"
   },
   "outputs": [],
   "source": [
    "#question_id, winner, hardness_score\n",
    "\n",
    "s1 = df_test['question_id']\n",
    "\n",
    "# replace with real data\n",
    "s2 = pd.Series(class_predictions, index=s1.index, name='winner')\n",
    "\n",
    "s3 = pd.Series(Y_test_rounded.reshape(-1), name='hardness_score')\n",
    "\n",
    "# Combine into a DataFrame\n",
    "df_csv = pd.concat([s1, s2, s3], axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "df_csv.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFABm3Ytdbf-"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2TcSyr1dc7m",
    "outputId": "93f4a4ee-2cf1-4831-85e8-e7845abeef94"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# get features\n",
    "T_columns = ['topic_dim_' + str(num) for num in range(10)]\n",
    "RA_columns = [f'model_a_dim_{i}' for i in range(256)]\n",
    "T_columns.extend(RA_columns)\n",
    "\n",
    "num_feat = T_columns\n",
    "num_feat.append('Log prompt_length')\n",
    "\n",
    "tot_feat = num_feat.copy()\n",
    "tot_feat.append('prompt_embedding_cluster')\n",
    "\n",
    "# get design matrix\n",
    "X_train_2 = train[tot_feat]\n",
    "Y_train_2 = train[\"avg_hardness_score\"]\n",
    "\n",
    "X_valid_2 = validation[tot_feat]\n",
    "Y_valid_2 = validation[\"avg_hardness_score\"]\n",
    "\n",
    "# Column types\n",
    "categorical_features = ['prompt_embedding_cluster']\n",
    "numerical_features = num_feat\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# XGBoost model pipeline\n",
    "model_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(objective='reg:squarederror', n_estimators=50, reg_lambda=2, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "model_xgb.fit(X_train_2, Y_train_2)\n",
    "\n",
    "# Predict\n",
    "Y_pred = model_xgb.predict(X_valid_2)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "rmse = np.sqrt(mean_squared_error(Y_valid_2, Y_pred))\n",
    "print(f'RMSE: {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9XyR4KB7Suy",
    "outputId": "aa9de364-a2fe-4cba-a255-cfa6fd3822eb"
   },
   "outputs": [],
   "source": [
    "# CV function\n",
    "def compute_CV_error_xgb(X_train, Y_train, folds=10):\n",
    "    kf = KFold(n_splits=folds)\n",
    "    validation_errors = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # Split the data\n",
    "        split_X_train, split_X_valid = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y_train.iloc[train_idx], Y_train.iloc[valid_idx]\n",
    "\n",
    "        # Column types\n",
    "        categorical_features = ['prompt_embedding_cluster']\n",
    "        numerical_features = num_feat\n",
    "\n",
    "        # Preprocessing pipeline\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numerical_features),\n",
    "                ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "        # XGBoost model pipeline\n",
    "        model_xgb_cv = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', XGBRegressor(objective='reg:squarederror', n_estimators=100, reg_lambda=1, max_depth=4, random_state=42))\n",
    "        ])\n",
    "        '''\n",
    "        # XGBoost model pipeline\n",
    "        model_xgb_cv = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', XGBRegressor(objective='reg:squarederror', max_depth=3, n_estimators=75, reg_lambda=1, random_state=42))\n",
    "        ])\n",
    "\n",
    "\n",
    "        # Fit the model on the training split\n",
    "        model_xgb_cv.fit(split_X_train, split_Y_train)\n",
    "        split_Y_valid_pred = model_xgb_cv.predict(split_X_valid)\n",
    "\n",
    "        # Compute the RMSE on the validation split\n",
    "        rmse = np.sqrt(mean_squared_error(split_Y_valid_pred, split_Y_valid))\n",
    "        #error = rmse(split_Y_valid_pred, split_Y_valid)\n",
    "\n",
    "        validation_errors.append(rmse)\n",
    "\n",
    "    return validation_errors\n",
    "\n",
    "cv = compute_CV_error_xgb(train[tot_feat], train[\"avg_hardness_score\"], folds=5)\n",
    "print(f\"4-fold cross validation RMSE errors: {cv}\")\n",
    "avg_cv = np.mean(cv)\n",
    "print(\"Avg 4-fold CV RMSE: \", avg_cv)\n",
    "std_cv = np.std(cv)\n",
    "print(\"Std: \", std_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vP-DnTAMw6h",
    "outputId": "51ee8916-bf9d-48e1-d57e-443faf065232"
   },
   "outputs": [],
   "source": [
    "# Grid Search for Predictions\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Split into training and validation sets\n",
    "# #X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# train_grid, validation_grid = train_val_split(topic_and_hardness_b, 0.8)\n",
    "# X_train = train_grid[tot_feat]\n",
    "# Y_train = train_grid[\"avg_hardness_score\"]\n",
    "\n",
    "# # get validation data\n",
    "# X_valid = validation_grid[tot_feat]\n",
    "# Y_valid = validation_grid[\"avg_hardness_score\"]\n",
    "\n",
    "# # Define the model\n",
    "# xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# # Set the hyperparameter grid to search over\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 75, 100],  # Number of boosting rounds\n",
    "#     'max_depth': [2, 3, 6],           # Max depth of trees\n",
    "#     'reg_lambda': [1, 1.5],\n",
    "#     'min_child_weight': [3, 5, 10],\n",
    "# }\n",
    "# '''\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],  # Number of boosting rounds\n",
    "#     'max_depth': [3, 6, 9],           # Max depth of trees\n",
    "#     'learning_rate': [0.01, 0.1, 0.2], # Learning rate (eta)\n",
    "#     'subsample': [0.8, 1.0],          # Subsample ratio\n",
    "#     'colsample_bytree': [0.7, 0.8, 1.0] # Fraction of features for each tree\n",
    "# }\n",
    "# '''\n",
    "# # Set up the GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=xgb_model,\n",
    "#                            param_grid=param_grid,\n",
    "#                            scoring='neg_mean_squared_error',\n",
    "#                            cv=4,\n",
    "#                            n_jobs=-1,\n",
    "#                            verbose=1)\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # Print the best hyperparameters found\n",
    "# print(\"Best hyperparameters found: \", grid_search.best_params_)\n",
    "\n",
    "# # Predict using the best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred = best_model.predict(X_valid)\n",
    "\n",
    "# # Evaluate performance (RMSE)\n",
    "# rmse = np.sqrt(mean_squared_error(Y_valid, y_pred))\n",
    "# print(f'RMSE: {rmse:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "515wtnJslzQb"
   },
   "source": [
    "## Now for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwgWPHWNhDrX"
   },
   "outputs": [],
   "source": [
    "X_test_2 = df_test[tot_feat]\n",
    "Y_test_2 = model_xgb.predict(X_test_2)\n",
    "Y_test_2 = np.round(Y_test_2).astype(int)\n",
    "\n",
    "my_series_2 = pd.Series(Y_test_2.reshape(-1))\n",
    "print(\"Predict rounded Y data:\\n\")\n",
    "print(my_series_2.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YStBS_MunCIR"
   },
   "outputs": [],
   "source": [
    "s12 = df_test['question_id']\n",
    "\n",
    "s22 = pd.Series(class_predictions, index=s12.index, name='winner')\n",
    "\n",
    "s32 = pd.Series(Y_test_2.reshape(-1), name='hardness_score')\n",
    "\n",
    "# Combine into a DataFrame\n",
    "df_xgb_csv = pd.concat([s12, s22, s32], axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "df_xgb_csv.to_csv('output_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhwlK-hbKGiS"
   },
   "outputs": [],
   "source": [
    "#df_xgb_read = pd.read_csv('/content/drive/MyDrive/colab_notebooks/ds_200_gp/output_xgb_read.csv', usecols=['question_id', 'hardness_score'])\n",
    "\n",
    "#df_xgb_read['hardness_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOTB9SoaONFO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b4258acaea64dccb25cb4c67ff5f5cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "101a3d16480a4b0d957d9dabddb6e379": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1672a7049c1d4406a3a005686796d759": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cbdf502f90046e1abe9ba6c5b0de185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f683c604c004d76800699d0d53cb3d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64011419638b432f98df7a14c7ee5287",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cbc011f260144b30a2526c3a46aca3ee",
      "value": 466062
     }
    },
    "22d7f83f93c64ce2a505d0c94ce3da3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_101a3d16480a4b0d957d9dabddb6e379",
      "placeholder": "​",
      "style": "IPY_MODEL_3136556c50a0496aa51ccadfa411d024",
      "value": " 440M/440M [00:01&lt;00:00, 253MB/s]"
     }
    },
    "284337e9579f4ade96bf416932905e06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c7c2ed8f1334a1883a6c11924d5eceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae25026e33a441998bb0f00c218ffb87",
       "IPY_MODEL_de74c71f6eb0418cb32a0cf9ed4bd477",
       "IPY_MODEL_22d7f83f93c64ce2a505d0c94ce3da3e"
      ],
      "layout": "IPY_MODEL_ca68369b73b144a1b407191515b6ebf2"
     }
    },
    "3136556c50a0496aa51ccadfa411d024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "345270265e2047ceaa755822cfc363de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "391eb91bb0714e6b9f5157428d6b2b41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f24fa59e6c684a3caacf907d920628ef",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f7a93994fc34f159fa38f66c59331da",
      "value": 48
     }
    },
    "3a55a98038eb45f694ebec9d51fbd209": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "412069cd6fb24a05a6052f55d05a7054": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c9b8768fd6b4068bbd5c0d24502e994": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b4258acaea64dccb25cb4c67ff5f5cf",
      "placeholder": "​",
      "style": "IPY_MODEL_716e7344c59e4355befb5b7f841ca9e4",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "4df4621ce4ee48cab6944cc1d2bf0fb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1672a7049c1d4406a3a005686796d759",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_345270265e2047ceaa755822cfc363de",
      "value": 231508
     }
    },
    "5927feeb860b4680b51f548ec4f19a80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d4869db6c3c41168f4f19a4aac76eb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6306a3901f50423c96b8274e3ff3637a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eaaff999c7e14b598f0ae398009c7ad2",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb45483aefe2456c8471b6edc98dc82f",
      "value": 570
     }
    },
    "63ef3c1b03994087ba9c128df9a7876d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b93ebd3149e840dbbc70fff973a89294",
      "placeholder": "​",
      "style": "IPY_MODEL_ab857bc75a9748e89c881c2b6b6acb3b",
      "value": " 232k/232k [00:00&lt;00:00, 3.19MB/s]"
     }
    },
    "64011419638b432f98df7a14c7ee5287": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6552bffb3bff4be9b0bbdc999ad78942": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f7a93994fc34f159fa38f66c59331da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "716e7344c59e4355befb5b7f841ca9e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73bfb7657c544235ad078267b34a8d0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "771c5068f51041dcbca83245a351da54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_926b10e60fb246919557a9c1e4fe74ee",
      "placeholder": "​",
      "style": "IPY_MODEL_bb920d1955b4486abf1f24f254db33bb",
      "value": "tokenizer.json: 100%"
     }
    },
    "7c1ccce3a0ae4d66a8f2a56d11d306c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b49cec94b3c43dc8bc351c1036d5600",
       "IPY_MODEL_6306a3901f50423c96b8274e3ff3637a",
       "IPY_MODEL_cdece558ede34a228b58dd0883649c28"
      ],
      "layout": "IPY_MODEL_f6c076f8897e4548a2bebf58d847570b"
     }
    },
    "8900c78610374afea2b6bd7ad1cb43a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b3d2d0d3e6a44eeb3a6ac71186296bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b49cec94b3c43dc8bc351c1036d5600": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a55a98038eb45f694ebec9d51fbd209",
      "placeholder": "​",
      "style": "IPY_MODEL_284337e9579f4ade96bf416932905e06",
      "value": "config.json: 100%"
     }
    },
    "9114c70e45fc431789a66a67458ded65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "926b10e60fb246919557a9c1e4fe74ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a878ebd0e28d4f5396beb5078875640d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_771c5068f51041dcbca83245a351da54",
       "IPY_MODEL_1f683c604c004d76800699d0d53cb3d7",
       "IPY_MODEL_ebc0a4832ba84d6c88e6c39f8071b802"
      ],
      "layout": "IPY_MODEL_8900c78610374afea2b6bd7ad1cb43a8"
     }
    },
    "a9c371dc3bb14012bb139494632b9c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab857bc75a9748e89c881c2b6b6acb3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae25026e33a441998bb0f00c218ffb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9114c70e45fc431789a66a67458ded65",
      "placeholder": "​",
      "style": "IPY_MODEL_8b3d2d0d3e6a44eeb3a6ac71186296bf",
      "value": "model.safetensors: 100%"
     }
    },
    "b232e1d0c3594842bec85f794fcbf8cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d4869db6c3c41168f4f19a4aac76eb2",
      "placeholder": "​",
      "style": "IPY_MODEL_1cbdf502f90046e1abe9ba6c5b0de185",
      "value": " 48.0/48.0 [00:00&lt;00:00, 2.33kB/s]"
     }
    },
    "b93ebd3149e840dbbc70fff973a89294": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb920d1955b4486abf1f24f254db33bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca68369b73b144a1b407191515b6ebf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb45483aefe2456c8471b6edc98dc82f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cbc011f260144b30a2526c3a46aca3ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ccb5629999264f9480e5597710dd9fd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdece558ede34a228b58dd0883649c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccb5629999264f9480e5597710dd9fd6",
      "placeholder": "​",
      "style": "IPY_MODEL_73bfb7657c544235ad078267b34a8d0f",
      "value": " 570/570 [00:00&lt;00:00, 55.2kB/s]"
     }
    },
    "d02355537c3646918cb6770caed23d11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0696195167f4455aad06dd0378cdde0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c9b8768fd6b4068bbd5c0d24502e994",
       "IPY_MODEL_391eb91bb0714e6b9f5157428d6b2b41",
       "IPY_MODEL_b232e1d0c3594842bec85f794fcbf8cf"
      ],
      "layout": "IPY_MODEL_6552bffb3bff4be9b0bbdc999ad78942"
     }
    },
    "d609ef7b77dc4597af6d56b0da9c0512": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de74c71f6eb0418cb32a0cf9ed4bd477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d02355537c3646918cb6770caed23d11",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f59b3ff1a1e9492687fd7173b28953cf",
      "value": 440449768
     }
    },
    "e49264837fc14e4eb52b24c9ae6ecda1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaaff999c7e14b598f0ae398009c7ad2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebc0a4832ba84d6c88e6c39f8071b802": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e49264837fc14e4eb52b24c9ae6ecda1",
      "placeholder": "​",
      "style": "IPY_MODEL_5927feeb860b4680b51f548ec4f19a80",
      "value": " 466k/466k [00:01&lt;00:00, 322kB/s]"
     }
    },
    "f24fa59e6c684a3caacf907d920628ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f59b3ff1a1e9492687fd7173b28953cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6c076f8897e4548a2bebf58d847570b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6da3637d48d405c8f69ee75b4257914": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d609ef7b77dc4597af6d56b0da9c0512",
      "placeholder": "​",
      "style": "IPY_MODEL_a9c371dc3bb14012bb139494632b9c1a",
      "value": "vocab.txt: 100%"
     }
    },
    "fe2eb57a2d2d4ce59d1c423f3fdf1ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6da3637d48d405c8f69ee75b4257914",
       "IPY_MODEL_4df4621ce4ee48cab6944cc1d2bf0fb3",
       "IPY_MODEL_63ef3c1b03994087ba9c128df9a7876d"
      ],
      "layout": "IPY_MODEL_412069cd6fb24a05a6052f55d05a7054"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
